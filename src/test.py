import asyncio
from ddgs import DDGS
from crawl4ai import AsyncWebCrawler


# 1. Láº¥y link Ä‘áº§u tá»« query (Æ°u tiÃªn DuckDuckGo hoáº·c SearxNG)
def get_first_search_link(query: str) -> str | None:
    with DDGS(timeout=60) as ddg:
        results = list(ddg.text(query, max_results=1, backend="lite"))
        print(f"ğŸ” DuckDuckGo results: {results}")
        if results:
            return results[0]["href"]
    return None


# 2. HÃ m chÃ­nh cháº¡y end-to-end
async def auto_crawl_from_query(query: str, max_links: int = 5):
    hub_url = get_first_search_link(query)
    if not hub_url:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y link nÃ o tá»« query")
        return

    print(f"ğŸ” Found hub URL: {hub_url}")

    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(url=hub_url, max_links=max_links)
        return result.markdown if result else "âŒ KhÃ´ng crawl Ä‘Æ°á»£c dá»¯ liá»‡u"


# 3. Thá»­ nghiá»‡m
if __name__ == "__main__":
    query = "site:laodong.vn Vinamilk tin tá»©c"
    asyncio.run(auto_crawl_from_query(query, max_links=10))
